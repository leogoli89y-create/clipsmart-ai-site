import { GoogleGenAI, Type } from "@google/genai";
import { Clip, ClipStyle } from "../types";

// Initialize the API client
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY || '' });

// Helper to ensure DOMException compatibility across environments (Browser vs Node)
// This avoids "ReferenceError: DOMException is not defined" if the environment doesn't support it globally.
function createDOMException(message: string, name: string): Error {
  if (typeof DOMException !== 'undefined') {
    return new DOMException(message, name);
  }
  const error = new Error(message);
  error.name = name;
  return error;
}

const fileToGenerativePart = async (file: File): Promise<{ inlineData: { data: string; mimeType: string } }> => {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    
    reader.onload = () => {
      if (reader.result) {
        const base64Data = (reader.result as string).split(',')[1];
        resolve({
          inlineData: {
            data: base64Data,
            mimeType: file.type,
          },
        });
      } else {
        reject(createDOMException("Falha ao ler dados do arquivo.", "NotReadableError"));
      }
    };

    reader.onerror = () => {
      reject(reader.error || createDOMException("Erro desconhecido na leitura do arquivo.", "UnknownError"));
    };

    reader.readAsDataURL(file);
  });
};

export const analyzeVideoForClips = async (
  videoInput: File | string, 
  style: ClipStyle
): Promise<Clip[]> => {
  try {
    // If input is a URL (YouTube), simulate response
    if (typeof videoInput === 'string') {
      console.log("Processing YouTube URL simulation...");
      await new Promise(resolve => setTimeout(resolve, 3000)); 
      
      const mockClips = [
        {
          title: "POV: Voc√™ n√£o vai acreditar üò±",
          summary: "Um momento insano que prende a aten√ß√£o do in√≠cio ao fim.",
          viralCaption: "Isso mudou tudo! ü§Ø Espere at√© o final... #viral #shocking #mustwatch",
          startTime: 30,
          endTime: 45,
          viralityScore: 9.8,
          transcript: "Voc√™s n√£o v√£o acreditar no que aconteceu aqui! √â simplesmente insano e mudou completamente a nossa percep√ß√£o."
        },
        {
          title: "Segredo Revelado ü§´",
          summary: "A dica de ouro que estava escondida no v√≠deo.",
          viralCaption: "Quem mais sabia disso? Salva pra n√£o esquecer! üëá #dicas #lifehack #segredo",
          startTime: 120,
          endTime: 135,
          viralityScore: 9.2,
          transcript: "O segredo fundamental para entender isso √© olhar para os detalhes min√∫sculos que a maioria das pessoas ignora."
        },
        {
          title: "Plot Twist do Ano üî•",
          summary: "O desfecho surpreendente que ningu√©m esperava.",
          viralCaption: "Eu N√ÉO estava esperando por essa! üíÄ Comenta se voc√™ adivinhou! #plottwist #surpresa",
          startTime: 200,
          endTime: 215,
          viralityScore: 9.5,
          transcript: "E foi exatamente nesse momento que tudo mudou para sempre. A resposta estava na nossa frente o tempo todo."
        }
      ];

      return mockClips.map((c, index) => ({
        id: `yt-clip-${Date.now()}-${index}`,
        title: c.title,
        summary: c.summary,
        viralCaption: c.viralCaption,
        startTime: c.startTime,
        endTime: c.endTime,
        viralityScore: c.viralityScore,
        category: style,
        transcript: c.transcript
      }));
    }

    // Normal File Processing
    const videoPart = await fileToGenerativePart(videoInput);

    let styleInstruction = "";
    switch (style) {
      case ClipStyle.FUNNY:
        styleInstruction = "Priorize humor, risadas e situa√ß√µes inusitadas.";
        break;
      case ClipStyle.EMOTIONAL:
        styleInstruction = "Priorize emo√ß√£o, inspira√ß√£o e conex√£o humana.";
        break;
      case ClipStyle.INFORMATIVE:
        styleInstruction = "Priorize fatos, 'sabia que?', e dicas √∫teis.";
        break;
      default:
        styleInstruction = "Priorize alta energia, cortes r√°pidos e momentos chocantes.";
    }

    const prompt = `
      Atue como um Engenheiro de √Åudio S√™nior e Especialista em Conte√∫do Viral.
      
      Sua tarefa √© analisar o v√≠deo (visual e √°udio) para extrair clipes de alt√≠ssima qualidade.

      DIRETRIZES RIGOROSAS DE √ÅUDIO E TRANSCRI√á√ÉO:
      1. **Isolamento Vocal**: O v√≠deo pode ter ru√≠do de fundo, m√∫sica ou interfer√™ncias. Sua prioridade √© isolar a voz principal. Utilize o contexto visual (leitura labial) para desambiguar palavras se o √°udio estiver confuso.
      2. **Corre√ß√£o de Dic√ß√£o e Sotaque**: Se houver sotaques fortes, fala muito r√°pida ou g√≠rias, transcreva o texto em portugu√™s padr√£o claro, mantendo a inten√ß√£o original. O objetivo √© legibilidade total.
      3. **Sincronia Exata**: O 'transcript' deve conter APENAS o que √© dito entre 'startTime' e 'endTime'. N√£o inclua palavras cortadas no in√≠cio ou no fim.
      4. **Limpeza Editorial**: Remova hesita√ß√µes ("√©...", "hum", "tipo assim") e repeti√ß√µes gaguejadas. A legenda deve ser limpa, profissional e direta.

      ${styleInstruction}
      
      Sua miss√£o: Identificar 3 a 4 trechos (Golden Moments) com potencial viral.
      Crit√©rios de corte:
      - Gancho (Hook) forte nos primeiros 3 segundos.
      - Conte√∫do que gera reten√ß√£o.
      
      Para cada clipe, gere JSON com:
      - title: T√≠tulo curto e apelativo.
      - summary: Descri√ß√£o t√©cnica do que acontece.
      - viralCaption: Uma legenda pronta para postar, usando gatilhos mentais, emojis e 3 hashtags relevantes.
      - startTime / endTime: Segundos exatos (float).
      - viralityScore: Nota 1-10 baseada no potencial de engajamento.
      - transcript: Transcri√ß√£o limpa, corrigida e perfeitamente sincronizada.
    `;

    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: {
        parts: [videoPart, { text: prompt }]
      },
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.ARRAY,
          items: {
            type: Type.OBJECT,
            properties: {
              title: { type: Type.STRING },
              summary: { type: Type.STRING },
              viralCaption: { type: Type.STRING, description: "Social media caption with emojis and hashtags" },
              startTime: { type: Type.NUMBER },
              endTime: { type: Type.NUMBER },
              viralityScore: { type: Type.NUMBER },
              transcript: { type: Type.STRING },
            },
            required: ["title", "summary", "viralCaption", "startTime", "endTime", "viralityScore", "transcript"]
          }
        }
      }
    });

    const jsonText = response.text || "[]";
    const rawClips = JSON.parse(jsonText);

    return rawClips.map((c: any, index: number) => ({
      id: `clip-${Date.now()}-${index}`,
      title: c.title,
      summary: c.summary,
      viralCaption: c.viralCaption || c.summary,
      startTime: Number(c.startTime),
      endTime: Number(c.endTime),
      viralityScore: c.viralityScore,
      category: style,
      transcript: c.transcript
    }));

  } catch (error: any) {
    console.error("Error analyzing video:", error);
    
    // Check if error is a DOMException (either native or our fallback)
    // We check name property to be generic across implementations
    const isDOMException = (typeof DOMException !== 'undefined' && error instanceof DOMException) || 
                           (error instanceof Error && (error.name === 'NotReadableError' || error.name === 'OperationError'));

    if (isDOMException) {
      throw error;
    }
    
    throw createDOMException(
      "Falha ao analisar o v√≠deo. Tente um arquivo menor ou verifique sua conex√£o.",
      "OperationError"
    );
  }
};

// Function for smart cut refinement
export const refineClip = async (clip: Clip): Promise<Clip> => {
    // In a real scenario, this would re-send the clip context to Gemini to ask for better start/end times
    // For this demo, we mock the intelligence or could re-call generateContent with just timestamps if needed.
    
    // Simulating "AI Thinking" about audio waves and visual cues
    return new Promise((resolve) => {
        setTimeout(() => {
            resolve(clip);
        }, 1000);
    });
};